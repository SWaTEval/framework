{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9122eda-a18a-45a4-9fda-4f57353d0e1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c38348-9f07-4198-b0ee-170e97d5a37e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluated data from literature\n",
    "\n",
    "**Note:** Run the *Apps Evaluation.ipynb* notebook first to generate the evaluation data \n",
    "\n",
    "**Note 2:** You can also use the already generated data from the `evaluation-data` repository present in the `raw/papers` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9cc846-4a7c-4285-838f-6777a0f109d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"**path to the generated app evaluation data**\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23feaa-5e4d-4ddc-b72f-4be190000b00",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred_matrix):\n",
    "    eval_results = pd.DataFrame()\n",
    "    for metric in y_pred_matrix.columns:\n",
    "        y_pred = y_pred_matrix[metric]\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        row = pd.Series({'TP':tp,'TN':tn,'FP':fp,'FN':fn,'Accuracy': accuracy, 'Recall':recall, 'Precision': precision, 'F1':f1},name=metric)\n",
    "        eval_results = eval_results.append(row)\n",
    "    return eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef2af51-27b1-4a09-82d5-ee0d394aff8b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filenames = os.listdir(directory)\n",
    "filecount = len(filenames)\n",
    "eval_results_sum = 0\n",
    "for filename in filenames:\n",
    "    filepath = f\"{directory}/{filename}\"\n",
    "    if os.path.isdir(filepath):\n",
    "        continue\n",
    "    results = pd.read_csv(filepath).drop(['state1','state2'], axis=1).astype(int)\n",
    "    y_true = results.iloc[:,-1] # Extract the human classified labels\n",
    "    y_pred_matrix = results.iloc[:,0:len(results.columns)-1] # Extract the classified labels\n",
    "    eval_results = evaluate(y_true, y_pred_matrix)\n",
    "    eval_results.to_csv(f'processed_{filename}')\n",
    "    eval_results_sum += eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788c19f-dbfb-479d-9a4b-26cabb6a448f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_results_average = eval_results_sum/filecount\n",
    "eval_results_average.to_csv(f'all_apps_avereged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c83182-8170-4482-8601-509a656c16d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_results_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a6289-416f-45ec-b546-41f65095e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_theirs = eval_results_average.T[['DOM_contentHash', 'DOM_Levenshtein', 'TLSH_hash2vec']]\n",
    "extracted_theirs = extracted_theirs.rename(columns={'DOM_contentHash': 'TLSH Score (Hash)', 'DOM_Levenshtein': 'Levenshtein (DOM)', 'TLSH_hash2vec':'Euclidean (Hash)'})\n",
    "extracted_theirs = extracted_theirs.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9ef6f7-6f3e-4b89-a077-16c8f021adef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Extract data from our evaluation framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d02330c-0a09-47a2-b4c8-52c3d6982628",
   "metadata": {},
   "source": [
    "**Note:** You can also use the already generated data from the `evaluation-data` repository present in the `raw/evaluation framework` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890c0fd6-b47d-4dbb-9ee0-6b90927f84b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "directory = \"**Path to the directory where the data from our evaluation is contained*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e752efd-4805-4f61-8a11-aed2401b927c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(directory + '/endpoints.json') as f:\n",
    "    endpoints = json.load(f)\n",
    "\n",
    "with open(directory + '/interactions.json') as f:\n",
    "    interactions = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28e2a93-86c8-4034-94f3-edf426ff4fb5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Parsing interactions as states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b8a8a-b667-4bba-9966-e973662b7e1d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "state_names = list()\n",
    "clustering_input = list()\n",
    "for interaction in tqdm(interactions):\n",
    "    state_hash = interaction['hash']\n",
    "    state_name = interaction['_id']['$oid']\n",
    "    dom = interaction['response']['data']\n",
    "    clustering_input.append({'name': state_name, 'hash': state_hash, 'dom':dom})\n",
    "    state_names.append(state_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3601ddb-02e0-4252-b6ea-681fa764cfef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..') # Allow relative imports\n",
    "from scanner.Detection.ClusteringBased.Clustering.DBSCANClustering import DBSCANClustering\n",
    "clustering = DBSCANClustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f0a986-efed-4198-a775-3114918f6a31",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_clusters_nativ, labels_nativ = clustering.cluster(clustering_input, distance_type='tlsh', field_for_index='name')\n",
    "print(f'DBSCAN TLSH Nativ found {n_clusters_nativ} clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1916f73e-f1f2-4762-bec6-4b5d58d91e31",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_clusters_hash2vec, labels_hash2vec = clustering.cluster(clustering_input, distance_type='hash2vec', field_for_index='name')\n",
    "print(f'DBSCAN TLSH Hash2Vec found {n_clusters_hash2vec} clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581439d8-0d1b-442e-adc9-0594b83cec08",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_clusters_levenshtein_dom, labels_levenshtein_dom = clustering.cluster(clustering_input, distance_type='levenshtein', field_for_index='dom')\n",
    "print(f'DBSCAN TLSH Levenshtain DOM found {n_clusters_levenshtein_dom} clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b6560-34ea-4631-bbb2-8d4791b530c1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "state_pairs = list(itertools.combinations(state_names,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63e76a-484e-4102-b842-dc6442b45968",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def detect_duplicates(labels, state_pairs, state_names):\n",
    "    duplicate_states = []\n",
    "    for state_pair in tqdm(state_pairs):\n",
    "        first_state_idx = state_names.index(state_pair[0])\n",
    "        first_state_label = labels[first_state_idx]\n",
    "\n",
    "        second_state_idx = state_names.index(state_pair[1])\n",
    "        second_state_label = labels[second_state_idx]\n",
    "\n",
    "        if first_state_label == second_state_label:\n",
    "            duplicate_states.append(state_pair)\n",
    "    return duplicate_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016a3df1-42d1-439d-8cf2-ab92666a6d79",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "our_duplicates_dbscan_tlsh_nativ = detect_duplicates(labels_nativ, state_pairs, state_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f980d-04a3-4d5a-be38-45bef24b2b6a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Duplicates found with our TLSH nativ method: {len(our_duplicates_dbscan_tlsh_nativ)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725d8673-d74a-4900-9a42-9787362b399e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "our_duplicates_dbscan_tlsh_hash2vec = detect_duplicates(labels_hash2vec, state_pairs, state_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3446edfe-50bc-4405-bfeb-28b9cd7828f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Duplicates found with our TLSH Hash2Vec method: {len(our_duplicates_dbscan_tlsh_hash2vec)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968ab825-0c87-4910-a33a-2a4563011431",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "our_duplicates_dbscan_levenshtain_dom = detect_duplicates(labels_levenshtein_dom, state_pairs, state_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2007d180-a6eb-48f8-b96a-54306f182bbd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Duplicates found with our TLSH Levenshtain DOM method: {len(our_duplicates_dbscan_levenshtain_dom)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32d19c7-15b1-4c14-8acf-a44353edc8e3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_classified_bool_array(duplicate_state_pairs):\n",
    "    bool_array = []\n",
    "    for state_pair in state_pairs:\n",
    "        if state_pair in duplicate_state_pairs:\n",
    "            bool_array.append(True)\n",
    "        else:\n",
    "            bool_array.append(False)\n",
    "    return bool_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7272d5-d0dc-4197-9ad6-d4f3a93627cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_state_interaction_path(state_name):\n",
    "    for interaction in interactions:\n",
    "        if interaction['_id']['$oid'] == state_name:\n",
    "            return interaction['request']['endpoint']['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e263c222-3c02-4c88-96d9-bcabb52432df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ground_truth_bool_array = list()\n",
    "for state_pair in state_pairs:\n",
    "    first_state_name = state_pair[0]\n",
    "    second_state_name = state_pair[1]\n",
    "\n",
    "    first_state_interaction_path = find_state_interaction_path(first_state_name)\n",
    "    second_state_interaction_path = find_state_interaction_path(second_state_name)\n",
    "\n",
    "    duplicates = False\n",
    "    if first_state_interaction_path == second_state_interaction_path:\n",
    "        duplicates = True\n",
    "\n",
    "    ground_truth_bool_array.append(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662f84f7-be7b-4fa3-92a2-91bf10f284d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['state1'] = [i[0] for i in state_pairs]\n",
    "results['state2'] = [i[1] for i in state_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb7db26-ce03-4430-b43e-832597835ccc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results['TLSH_nativ'] = create_classified_bool_array(our_duplicates_dbscan_tlsh_nativ)\n",
    "results['TLSH_hash2vec'] = create_classified_bool_array(our_duplicates_dbscan_tlsh_hash2vec)\n",
    "results['Levenshtain_Dom'] = create_classified_bool_array(our_duplicates_dbscan_levenshtain_dom)\n",
    "results['Ground Truth'] = ground_truth_bool_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48882126-a050-40f7-a929-11b45dd7e6d7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c64f44-680c-454f-8df9-b47a0e3b0e13",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluation = results.drop(['state1','state2'], axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f42faed-239d-4f14-9ce9-673221e222d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_true = evaluation.iloc[:,-1] # Extract the human classified labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cef2170-16e9-426e-8b67-af829cd90177",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_matrix = evaluation.iloc[:,0:len(evaluation.columns)-1] # Extract the classified labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb23b1-8cfb-4a2e-aa72-d3a647e9c500",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "eval_results = pd.DataFrame()\n",
    "\n",
    "for metric in y_pred_matrix.columns:\n",
    "    y_pred = y_pred_matrix[metric]\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    row = pd.Series({'TP':tp,'TN':tn,'FP':fp,'FN':fn,'Accuracy': accuracy, 'Recall':recall, 'Precision': precision, 'F1':f1},name=metric)\n",
    "\n",
    "    eval_results = eval_results.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e52585-2716-400f-9ffe-fec7ec559308",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab6c0ae-3b15-42c4-b202-99c38d827e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracte_ours = eval_results.T[['TLSH_nativ', 'Levenshtain_Dom', 'TLSH_hash2vec']]\n",
    "extracte_ours = extracte_ours.rename(columns={'TLSH_nativ': 'TLSH Score (Hash)', 'Levenshtain_Dom': 'Levenshtein (DOM)', 'TLSH_hash2vec':'Euclidean (Hash)'})\n",
    "extracte_ours = extracte_ours.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56aa53-7c44-458e-96b2-80123add6917",
   "metadata": {},
   "source": [
    "# Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c121070f-821d-432d-a5f4-3c854b27f0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_theirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bcab26-5d52-4e09-b27d-f74cc681895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracte_ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6074f4ce-2313-46fc-bec3-512954742102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Numbers of pairs of bars you want\n",
    "N = 3\n",
    "\n",
    "# Position of bars on x-axis\n",
    "ind = np.arange(N)\n",
    "\n",
    "# Width of a bar\n",
    "width = 0.3\n",
    "offset = 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6,3))\n",
    "distance_metrics = list(extracte_ours.index)\n",
    "\n",
    "acc_ours = extracte_ours['Accuracy']\n",
    "acc_ours = round(acc_ours,2)\n",
    "acc_ours = acc_ours[['Euclidean (Hash)', 'TLSH Score (Hash)', 'Levenshtein (DOM)']]\n",
    "\n",
    "acc_theirs = extracted_theirs['Accuracy']\n",
    "acc_theirs = round(acc_theirs,2)\n",
    "acc_theirs = acc_theirs[['Euclidean (Hash)', 'TLSH Score (Hash)', 'Levenshtein (DOM)']]\n",
    "\n",
    "ax.grid(linestyle = '--', linewidth = 0.5, axis = 'y', zorder=0)\n",
    "\n",
    "ax.bar(ind, acc_theirs, width, zorder=3)\n",
    "\n",
    "#ax.bar(ind, acc_theirs, width, yerr=acc_theirs.std(),zorder=3, capsize=5)\n",
    "ax.bar(ind + width + offset, acc_ours, width, zorder=3)\n",
    "#ax.bar(ind + width + offset, acc_ours, width, yerr=acc_ours.std(), zorder=3, capsize=5)\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container)\n",
    "\n",
    "ax.set_title(\"Duplicate Detection Accuracy of Different Similarity Metrics\")\n",
    "ax.set_xlabel(\"Similarity Metric\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "\n",
    "ax.set_xticks(ind + width / 2, ['Euclidean', 'TLSH Score', 'Levenshtein'])\n",
    "ax.set_ylim(0,1.1)\n",
    "\n",
    "ax.legend(['Data by Yandrapally et al.', 'Our Evaluation Target'],loc='upper center', bbox_to_anchor=(0.5, -0.2),\n",
    "      fancybox=True, shadow=False, ncol=2)\n",
    "\n",
    "plt.savefig('distance_metrics_accuracy_ours_vs_literature.svg', bbox_inches='tight', format='svg')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
